{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn import mixture\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import glob\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "abdullah_training_directory = './images/Abdullah/training/'\n",
    "mustafa_training_directory = './images/Mustafa/training/'\n",
    "saleh_training_directory = './images/Saleh/training/'\n",
    "adham_training_directory = './images/Adham/training/'\n",
    "\n",
    "abdullah_testing_directory = './images/Abdullah/testing/'\n",
    "mustafa_testing_directory = './images/Mustafa/testing/'\n",
    "saleh_testing_directory = './images/Saleh/testing/'\n",
    "adham_testing_directory = './images/Adham/testing/'\n",
    "\n",
    "\n",
    "training_images_directories = [abdullah_training_directory, mustafa_training_directory, saleh_training_directory, adham_training_directory]\n",
    "testing_images_directories = [abdullah_testing_directory, mustafa_testing_directory, saleh_testing_directory, adham_testing_directory]\n",
    "\n",
    "training_images = []\n",
    "testing_images = []\n",
    "\n",
    "# Load the cascade for facial detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "# Populate Training Image list\n",
    "for directory in training_images_directories:\n",
    "    images = [cv2.imread(file) for file in glob.glob(\"{directory}*.jpg\".format(directory=directory))]\n",
    "    for img in images:\n",
    "        training_images.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "# Populate Testing Image list\n",
    "for directory in testing_images_directories:\n",
    "    images = [cv2.imread(file) for file in glob.glob(\"{directory}*.jpg\".format(directory=directory))]\n",
    "    for img in images:\n",
    "        testing_images.append(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\"\"\"\n",
    "4.1 + 4.3 --- Training Images Feature Extraction using SIFT\n",
    "\"\"\"\n",
    "\n",
    "# create a SIFT object\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "training_bounds = []\n",
    "\n",
    "for i in range(60):\n",
    "    img = training_images[i]\n",
    "    # copy image\n",
    "    img_disp = img.copy()\n",
    "    # convert to grayscale\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # detect harris corners\n",
    "    # cv2.cornerHarris(src, neighborhoodsize, sobelKernelSize, Harris_k)\n",
    "    corners = cv2.cornerHarris(img_gray, 2, 3, 0.04)\n",
    "\n",
    "    # normalize corner map [0,1]\n",
    "    # cv2.normalize(src, dst, alpha, beta, norm_type)\n",
    "    # min_I(dst(I)) = alpha, max_I(dst(I)) = beta\n",
    "    cv2.normalize(corners, corners, 0, 1, cv2.NORM_MINMAX)\n",
    "\n",
    "    # threshold for an optimal value\n",
    "    thres = 0.5\n",
    "\n",
    "    # list all points higher than threshold\n",
    "    loc = np.where(corners >= thres)\n",
    "    # loop though points\n",
    "    \n",
    "    pts = []\n",
    "    \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        pts.append(pt)\n",
    "        \n",
    "        # draw filled circle on each point\n",
    "        cv2.circle(img_disp, pt, 4, (255,0,0), -1)\n",
    "\n",
    "    xs, ys = np.array(list(zip(*pts)))\n",
    "    bounds_dict = {\"min_x\" : np.amin(xs), \"min_y\" : np.amin(ys), \"max_x\" : np.amax(xs), \"max_y\" : np.amax(ys)}\n",
    "    training_bounds.append(bounds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_face(img, bounds):\n",
    "    min_x =  bounds[\"min_x\"]\n",
    "    max_x =  bounds[\"max_x\"]\n",
    "    min_y =  bounds[\"min_y\"]\n",
    "    max_y =  bounds[\"max_y\"]\n",
    "\n",
    "    return img[min_y:max_y, min_x:max_x,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 80))\n",
    "training_faces = []\n",
    "for i in range(60):\n",
    "    img = training_images[i]\n",
    "    face = extract_face(img, training_bounds[i])\n",
    "    face = cv2.resize(face, (128,128))\n",
    "    training_faces.append(face)\n",
    "     # display images\n",
    "    plt.subplot(15, 4, i+1)\n",
    "    plt.imshow(face)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(training_faces).reshape(len(training_faces), -1)\n",
    "pca = PCA(n_components=15)\n",
    "pca.fit(X_train)\n",
    "\n",
    "plt.imshow(pca.mean_.reshape(training_faces[0].shape).astype('uint8'), cmap='gray')\n",
    "plt.title('Mean Image');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "for i in range(5):\n",
    "    ax = fig.add_subplot(1, 5, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(pca.components_[i].reshape(training_faces[0].shape).astype('uint8'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
